{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BigEarthNet CNN for uniquely labelled 46 classes",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "119rRHSflum0Dv2It9Vuco6A6nGlcddxw",
      "authorship_tag": "ABX9TyMKjnpse/sAy9QFWeBZ81yJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BRIJNANDA1979/BIGEARTHNET/blob/main/BigEarthNet_CNN_for_uniquely_labelled_46_classes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMEsja1YQzEX"
      },
      "source": [
        "BigEarthNet unique labelled data with 46 classes from data uploaded on google drive.\n",
        "\n",
        "Step  1: to create geotiff image using 12 bands of Sentinel-2 imagery \n",
        "Step 2 :  to create batch of data with labels\n",
        "Step 3: Normalize data\n",
        "Step 4: Transform data in proper shape\n",
        "Step 5: Data input to CNN\n",
        "Step 6: Reslut and prediction of data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38zj194h_N_K"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJkMdq_SRXCG"
      },
      "source": [
        "import os\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4jAn9SORawY"
      },
      "source": [
        "src_path = '/content/drive/MyDrive/BigEarthNet unique labelled'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F41BZyhvUpsB",
        "outputId": "c2e9def0-3b24-4090-c743-70edd909945b"
      },
      "source": [
        "!pip install rasterio"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting rasterio\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/6e/b32a74bca3d4fca8286c6532cd5795ca8a2782125c23b383448ecd9a70b6/rasterio-1.2.6-cp37-cp37m-manylinux1_x86_64.whl (19.3MB)\n",
            "\u001b[K     |████████████████████████████████| 19.3MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rasterio) (1.19.5)\n",
            "Collecting affine\n",
            "  Downloading https://files.pythonhosted.org/packages/ac/a6/1a39a1ede71210e3ddaf623982b06ecfc5c5c03741ae659073159184cd3e/affine-2.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.7/dist-packages (from rasterio) (7.1.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from rasterio) (2021.5.30)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from rasterio) (21.2.0)\n",
            "Collecting click-plugins\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/da/824b92d9942f4e472702488857914bdd50f73021efea15b4cad9aca8ecef/click_plugins-1.1.1-py2.py3-none-any.whl\n",
            "Collecting snuggs>=1.4.1\n",
            "  Downloading https://files.pythonhosted.org/packages/cc/0e/d27d6e806d6c0d1a2cfdc5d1f088e42339a0a54a09c3343f7f81ec8947ea/snuggs-1.4.7-py3-none-any.whl\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rasterio) (57.0.0)\n",
            "Collecting cligj>=0.5\n",
            "  Downloading https://files.pythonhosted.org/packages/73/86/43fa9f15c5b9fb6e82620428827cd3c284aa933431405d1bcf5231ae3d3e/cligj-0.7.2-py3-none-any.whl\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.7/dist-packages (from snuggs>=1.4.1->rasterio) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMCHaqr1Ck0l"
      },
      "source": [
        "!pip install glob2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJtNRJ2tURZq"
      },
      "source": [
        "import rasterio\n",
        "from rasterio import merge\n",
        "import glob2\n",
        "def merge_bands(path,sub):\n",
        "    search = '*_B*.tif'   # 12 Band files end with B01,B02....\n",
        "    files_batch = []\n",
        "    files_batch = glob2.glob(os.path.join(path,search)) #search all tif band files \n",
        "    files_batch =sorted(files_batch)\n",
        "    print(files_batch) \n",
        "    print(len(files_batch))\n",
        "    if len(files_batch) == 0 or len(files_batch) > 12 :\n",
        "      print(len(files_batch))\n",
        "      print(\"Some folders are empty or already contain merged geotiff file and dont have 12 band files\")\n",
        "      return\n",
        "    # Read metadata of first file\n",
        "    with rasterio.open(files_batch[0]) as src0: #open first files out of batch of 12 files\n",
        "        meta = src0.meta\n",
        "\n",
        "    # Update meta to reflect the number of layers in merged output geotiff file\n",
        "    meta.update(count = len(files_batch)) #change output meta files as it will have 12 bands rather than 1 as in source files\n",
        "\n",
        "    # Read each layer and write it to stack\n",
        "    fnames = path +'/' + sub + '.tif'\n",
        "    with rasterio.open(fnames, 'w', **meta) as dst: #output/destination(dst) file opened in write mode with an extra \"meta\" arbitrary keyword argument\n",
        "        print(dst)\n",
        "        for id, layer in enumerate(files_batch, start=1): # create list of 12 tuples \n",
        "            print(id,layer)\n",
        "            with rasterio.open(layer) as src1:\n",
        "                dst.write_band(id, src1.read(1)) #read 1 band at a time and write it to stacled tif"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZTIbQoqRn7p"
      },
      "source": [
        "dirs = os.listdir(src_path)  #list of all classes\n",
        "print(dirs)\n",
        "print(len(dirs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "U8x8e2MH_Nyu"
      },
      "source": [
        "# TESTING the input data..before merging 12 bands to geotiff\n",
        "%%timeit\n",
        "import glob2 # glob2 is faster than glob\n",
        "for dir in dirs:\n",
        "  sub_dirs = os.listdir(os.path.join(src_path,dir))\n",
        "  src_folders_path = os.path.join(src_path,dir)\n",
        "  for sub in sub_dirs:\n",
        "    path=os.path.join(src_folders_path,sub)\n",
        "    #print(len(sub_dirs))\n",
        "    search = '*_B*.tif'   # 12 Band files end with B01,B02....\n",
        "    files_batch = []\n",
        "    files_batch = glob2.glob(os.path.join(path,search)) #search all tif band files \n",
        "    files_batch =sorted(files_batch)\n",
        "    #print(files_batch) \n",
        "    if len(files_batch) < 12:  # each source tif files folder must have 12 tif files\n",
        "      print(len(files_batch))\n",
        "      print(dir)\n",
        "      exit_parameter  = True\n",
        "      break\n",
        "    else:\n",
        "      continue\n",
        "    if exit_parameter == True:\n",
        "      break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YSgi0raIR50B"
      },
      "source": [
        "%%timeit\n",
        "import glob2 # glob2 is faster than glob\n",
        "\n",
        "for dir in dirs:\n",
        "  sub_dirs = os.listdir(os.path.join(src_path,dir))\n",
        "  path=os.path.join(src_path,dir)\n",
        "  print(dir,len(sub_dirs))\n",
        "  for data_folder in sub_dirs:\n",
        "    path_tif_files=os.path.join(path,data_folder)\n",
        "    search = '*.tif'  \n",
        "    files_batch = []\n",
        "    files_batch = glob2.glob(os.path.join(path_tif_files,search)) #search all tif band files \n",
        "    files_batch =sorted(files_batch)\n",
        "    if(len(files_batch)== 12):\n",
        "      merge_bands(path_tif_files,data_folder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sZhDQjayjMn-"
      },
      "source": [
        "import pandas as pd\n",
        "src_path='/content/drive/MyDrive/BigEarthNet unique labelled'\n",
        "classes = os.listdir(src_path)\n",
        "classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VojKzKu0k6Zf"
      },
      "source": [
        "data=[]\n",
        "labels=[]\n",
        "code=[]\n",
        "code_var=0\n",
        "for files in classes:\n",
        "  geotiff_files = os.listdir(os.path.join(src_path,files))\n",
        "  #print(geotiff_files)\n",
        "  print(len(geotiff_files))\n",
        "  for i in geotiff_files:\n",
        "    data.append(i)\n",
        "    labels.append(files)\n",
        "    code.append(code_var)\n",
        "  code_var = code_var+1\n",
        "  \n",
        "data\n",
        "labels\n",
        "code"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qv5LluzGpobK"
      },
      "source": [
        "df=pd.DataFrame()\n",
        "df['data'] = data\n",
        "df['labels'] = labels\n",
        "df['code'] = code\n",
        "df.head()\n",
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "H992acO0p-0a"
      },
      "source": [
        "df[0:670]\n",
        "df.shape\n",
        "#df.size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "20LXZq4yqnJn"
      },
      "source": [
        "from rasterio.plot import reshape_as_raster, reshape_as_image\n",
        "from rasterio.plot import adjust_band\n",
        "import numpy as np\n",
        "#print(files) #geotiff files\n",
        "\n",
        "fpath = '/content/drive/MyDrive/BigEarthNet unique labelled'\n",
        "\n",
        "batch=[]\n",
        "for row in df.itertuples():\n",
        "  f = fpath + '/' + row[2] + '/' + row[1] + '/' + row[1] + '.tif'\n",
        "  img_data = rasterio.open(f)\n",
        "  image = img_data.read()\n",
        "  image_norm = adjust_band(image) # normalize bands to range between 1.0 to 0.0\n",
        "  image_reshaped = reshape_as_image(image_norm) # reshape to [rows, cols, bands]\n",
        "  print(image_reshaped.shape)\n",
        "  print(img_data.shape)\n",
        "  batch.append(image_reshaped)\n",
        "print(len(batch))\n",
        "batch=np.asarray(batch)\n",
        "print(batch.shape)\n",
        "X=batch    # Input for CNN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IKcO3TJK1x19"
      },
      "source": [
        "print(len(classes))\n",
        "l=len(classes)\n",
        "code_classes = list(enumerate(classes,0))   # code the classes\n",
        "code_classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ouGj2rRn0ADf"
      },
      "source": [
        "#convert list to array\n",
        "import numpy as np\n",
        "batch=np.asarray(batch)\n",
        "print(batch.shape)\n",
        "y=df['code']\n",
        "print(y)\n",
        "y=np.array(y)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BHWXKk704RUc"
      },
      "source": [
        "print(X.shape)    # data is ready for CNN\n",
        "print(y.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TP4EcD1O4Xtq"
      },
      "source": [
        "print(batch[0])  #first tiff image normalized"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xXlB6Ldv4jRj"
      },
      "source": [
        "!pip install keras.utils\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "AMTxTL7f42uB"
      },
      "source": [
        "from keras.utils import np_utils\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)\n",
        "print(y_train.shape)\n",
        "y_train = np_utils.to_categorical(y_train, len(classes))\n",
        "y_test = np_utils.to_categorical(y_test, len(classes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QYL9VCSu6BHf"
      },
      "source": [
        "print(y_train[1681:1683])  # visualize y_train data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Uy8_2KPB6fW5"
      },
      "source": [
        "input_shape = (20,20,12)\n",
        "num_classes = len(classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MGv5nIax6yeA"
      },
      "source": [
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, BatchNormalization\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BKtmcRvZ610P"
      },
      "source": [
        "model = keras.models.Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), padding='same', input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Dense(128))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wV25eCox6_BJ"
      },
      "source": [
        "model.compile(\n",
        "   loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "odtyX1ad7Ftn"
      },
      "source": [
        "from keras.callbacks import EarlyStopping "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyrqObT57JSM"
      },
      "source": [
        "history = model.fit(X_train, y_train, batch_size = 30, epochs = 150, validation_data = (X_test, y_test),\n",
        "                    callbacks = [EarlyStopping(monitor = 'val_loss', patience = 20)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_gNz6fZx7P9h"
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose = 0) \n",
        "\n",
        "print('Test loss:', score[0]) \n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pfEWTrbY-EjI"
      },
      "source": [
        "pred = model.predict(X_test) \n",
        "pred = np.argmax(pred, axis = 1)[:100] \n",
        "label = np.argmax(y_test,axis = 1)[:100] \n",
        "\n",
        "print(pred) \n",
        "print(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_X6I7G_f-O0w"
      },
      "source": [
        "prediction = model.predict(X_test)\n",
        "print(prediction.flatten()) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WgUcy93ZDFTs"
      },
      "source": [
        "# Get the count of accurately predicted records - (1)\n",
        "print(sum(pred == label))\n",
        "# Get the count of total records - (2)\n",
        "print(len(pred))\n",
        "\n",
        "# Categorical Accuracy = (1)/(2)\n",
        "CalculatedCategoricalAccuracy = sum(pred == label)/len(pred)\n",
        "print(CalculatedCategoricalAccuracy)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8aNlI9_GPlM"
      },
      "source": [
        "# Plot training & validation accuracy values\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}