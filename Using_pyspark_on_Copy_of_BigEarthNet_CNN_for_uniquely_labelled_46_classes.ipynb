{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Using pyspark on Copy of BigEarthNet CNN for uniquely labelled 46 classes",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1jIe6juKVBQPOywC5EhEghyyTFIb64YYt",
      "authorship_tag": "ABX9TyO+lfJ+potkEw8Tmbh4XbR3",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BRIJNANDA1979/BIGEARTHNET/blob/main/Using_pyspark_on_Copy_of_BigEarthNet_CNN_for_uniquely_labelled_46_classes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMEsja1YQzEX"
      },
      "source": [
        "BigEarthNet unique labelled data with 46 classes from data uploaded on google drive.\n",
        "\n",
        "Step  1: to create geotiff image using 12 bands of Sentinel-2 imagery \n",
        "Step 2 :  to create batch of data with labels\n",
        "Step 3: Normalize data\n",
        "Step 4: Transform data in proper shape\n",
        "Step 5: Data input to CNN\n",
        "Step 6: Reslut and prediction of data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38zj194h_N_K"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJkMdq_SRXCG"
      },
      "source": [
        "import os\n",
        "import pandas as pd"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4jAn9SORawY"
      },
      "source": [
        "src_path = '/content/drive/MyDrive/BigEarthNet unique labelled'"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F41BZyhvUpsB",
        "outputId": "bc8f62ca-fd0d-41d9-f7ef-08281f08cd7e"
      },
      "source": [
        "!pip install rasterio"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rasterio in /usr/local/lib/python3.7/dist-packages (1.2.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rasterio) (1.19.5)\n",
            "Requirement already satisfied: snuggs>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from rasterio) (1.4.7)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from rasterio) (21.2.0)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.7/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rasterio) (57.0.0)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.7/dist-packages (from rasterio) (2.3.0)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.7/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from rasterio) (2021.5.30)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.7/dist-packages (from rasterio) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.7/dist-packages (from snuggs>=1.4.1->rasterio) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMCHaqr1Ck0l",
        "outputId": "f4c80f74-9919-4a6d-91f3-fd2ed76b0d7a"
      },
      "source": [
        "!pip install glob2"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: glob2 in /usr/local/lib/python3.7/dist-packages (0.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZTIbQoqRn7p",
        "outputId": "43ea4032-13e5-4ac2-819d-4072f285efeb"
      },
      "source": [
        "dirs = os.listdir(src_path)  #list of all classes\n",
        "print(dirs)\n",
        "print(len(dirs))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Agro-forestry areas', 'Airports', 'Annual crops associated with permanent crops', 'Coastal lagoons', 'Complex cultivation patterns', 'Discontinuous urban fabric', 'Dump sites', 'Estuaries', 'Fruit trees and berry plantations', 'Green urban areas', 'Industrial or commercial units', 'Inland marshes', 'Intertidal flats', 'Mineral extraction sites', 'Mixed forest', 'Moors and heathland', 'Natural grassland', 'Permanently irrigated land', 'Rice fields', 'Salt marshes', 'Sclerophyllous vegetation', 'Sparsely vegetated areas', 'Sport and leisure facilities', 'Transitional woodlandshrub', 'Non-irrigated arable land', 'Water bodies', 'Water courses', '.ipynb_checkpoints']\n",
            "28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "U8x8e2MH_Nyu"
      },
      "source": [
        "# TESTING the input data..before merging 12 bands to geotiff\n",
        "%%timeit\n",
        "import glob2 # glob2 is faster than glob\n",
        "for dir in dirs:\n",
        "  sub_dirs = os.listdir(os.path.join(src_path,dir))\n",
        "  src_folders_path = os.path.join(src_path,dir)\n",
        "  for sub in sub_dirs:\n",
        "    path=os.path.join(src_folders_path,sub)\n",
        "    #print(len(sub_dirs))\n",
        "    search = '*_B*.tif'   # 12 Band files end with B01,B02....\n",
        "    files_batch = []\n",
        "    files_batch = glob2.glob(os.path.join(path,search)) #search all tif band files \n",
        "    files_batch =sorted(files_batch)\n",
        "    #print(files_batch) \n",
        "    if len(files_batch) < 12:  # each source tif files folder must have 12 tif files\n",
        "      print(len(files_batch))\n",
        "      print(dir)\n",
        "      exit_parameter  = True\n",
        "      break\n",
        "    else:\n",
        "      continue\n",
        "    if exit_parameter == True:\n",
        "      break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZhDQjayjMn-"
      },
      "source": [
        "import pandas as pd\n",
        "src_path='/content/drive/MyDrive/BigEarthNet unique labelled'\n",
        "classes = os.listdir(src_path)\n",
        "classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEBg5-RTJF_Y"
      },
      "source": [
        "# Start PySpark session to read data in spark Dataframe\n",
        "\n",
        "!pip install pyspark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDL5mQ1ZJbn6"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "spark=SparkSession.builder.appName('BigEarthNet').getOrCreate()\n",
        "Df = spark.read.csv('/content/drive/MyDrive/Data/Data with Labels.csv',inferSchema=True, header =True)\n",
        "Df.printSchema()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypbX8PoTLlov"
      },
      "source": [
        "Df.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qv5LluzGpobK"
      },
      "source": [
        "Df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekTebMMiORkp"
      },
      "source": [
        "# Collect the data to Python List\n",
        "dataCollect = Df.collect()   #https://sparkbyexamples.com/pyspark/pyspark-loop-iterate-through-rows-in-dataframe/\n",
        "for row in dataCollect:\n",
        "    print(row[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20LXZq4yqnJn"
      },
      "source": [
        "import rasterio\n",
        "from rasterio.plot import reshape_as_raster, reshape_as_image\n",
        "from rasterio.plot import adjust_band\n",
        "import numpy as np\n",
        "#print(files) #geotiff files\n",
        "\n",
        "fpath = '/content/drive/MyDrive/BigEarthNet unique labelled'\n",
        "\n",
        "batch=[]\n",
        "for row in dataCollect:    # Using Spark dataframes\n",
        "  f = fpath + '/' + row[1] + '/' + row[0] + '/' + row[0] + '.tif'    \n",
        "  img_data = rasterio.open(f)\n",
        "  image = img_data.read()\n",
        "  image_norm = adjust_band(image) # normalize bands to range between 1.0 to 0.0\n",
        "  image_reshaped = reshape_as_image(image_norm) # reshape to [rows, cols, bands]\n",
        "  print(image_reshaped.shape)\n",
        "  print(img_data.shape)\n",
        "  batch.append(image_reshaped)\n",
        "print(len(batch))\n",
        "batch=np.asarray(batch)\n",
        "print(batch.shape)\n",
        "X=batch    # Input for CNN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IKcO3TJK1x19"
      },
      "source": [
        "print(len(classes))\n",
        "l=len(classes)\n",
        "code_classes = list(enumerate(classes,0))   # code the classes\n",
        "code_classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ouGj2rRn0ADf"
      },
      "source": [
        "#convert list to array\n",
        "import numpy as np\n",
        "batch=np.asarray(batch)\n",
        "print(batch.shape)\n",
        "y=dataCollect['code']\n",
        "print(y)\n",
        "y=np.array(y)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BHWXKk704RUc"
      },
      "source": [
        "print(X.shape)    # data is ready for CNN\n",
        "print(y.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TP4EcD1O4Xtq"
      },
      "source": [
        "print(batch[0])  #first tiff image normalized"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xXlB6Ldv4jRj"
      },
      "source": [
        "!pip install keras.utils\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "AMTxTL7f42uB"
      },
      "source": [
        "from keras.utils import np_utils\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)\n",
        "print(y_train.shape)\n",
        "y_train = np_utils.to_categorical(y_train, len(classes))\n",
        "y_test = np_utils.to_categorical(y_test, len(classes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QYL9VCSu6BHf"
      },
      "source": [
        "print(y_train[1681:1683])  # visualize y_train data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Uy8_2KPB6fW5"
      },
      "source": [
        "input_shape = (20,20,12)\n",
        "num_classes = len(classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MGv5nIax6yeA"
      },
      "source": [
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, BatchNormalization\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BKtmcRvZ610P"
      },
      "source": [
        "model = keras.models.Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), padding='same', input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Dense(128))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wV25eCox6_BJ"
      },
      "source": [
        "model.compile(\n",
        "   loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "odtyX1ad7Ftn"
      },
      "source": [
        "from keras.callbacks import EarlyStopping "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyrqObT57JSM"
      },
      "source": [
        "history = model.fit(X_train, y_train, batch_size = 30, epochs = 150, validation_data = (X_test, y_test),\n",
        "                    callbacks = [EarlyStopping(monitor = 'val_loss', patience = 20)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_gNz6fZx7P9h"
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose = 0) \n",
        "\n",
        "print('Test loss:', score[0]) \n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pfEWTrbY-EjI"
      },
      "source": [
        "pred = model.predict(X_test) \n",
        "pred = np.argmax(pred, axis = 1)[:100] \n",
        "label = np.argmax(y_test,axis = 1)[:100] \n",
        "\n",
        "print(pred) \n",
        "print(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_X6I7G_f-O0w"
      },
      "source": [
        "prediction = model.predict(X_test)\n",
        "print(prediction.flatten()) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WgUcy93ZDFTs"
      },
      "source": [
        "# Get the count of accurately predicted records - (1)\n",
        "print(sum(pred == label))\n",
        "# Get the count of total records - (2)\n",
        "print(len(pred))\n",
        "\n",
        "# Categorical Accuracy = (1)/(2)\n",
        "CalculatedCategoricalAccuracy = sum(pred == label)/len(pred)\n",
        "print(CalculatedCategoricalAccuracy)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8aNlI9_GPlM"
      },
      "source": [
        "# Plot training & validation accuracy values\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}